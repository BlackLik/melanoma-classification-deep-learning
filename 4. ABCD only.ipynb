{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from src import datasource\n",
    "\n",
    "sns.set_theme()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DATA_DIR = \"../data\"\n",
    "data_dir = f\"{MAIN_DATA_DIR}/all_data\"\n",
    "labels_file = Path(data_dir, \"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4976 entries, 0 to 4975\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   class     4976 non-null   object\n",
      " 1   filename  4976 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 77.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data = datasource.get_data_frame()\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = datasource.get_train_validate_test(df_data=df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"asymmetry\", \"border_irregularity\", \"color_variation\", \"diameter\", \"abcd_score\"]\n",
    "train_df = datasource.build_tabular_data(train)\n",
    "val_df = datasource.build_tabular_data(val)\n",
    "test_df = datasource.build_tabular_data(test)\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[\"label\"]\n",
    "X_val = val_df[features]\n",
    "y_val = val_df[\"label\"]\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.99264\teval-mlogloss:0.99414\n",
      "[1]\ttrain-mlogloss:0.90364\teval-mlogloss:0.90672\n",
      "[2]\ttrain-mlogloss:0.82813\teval-mlogloss:0.83339\n",
      "[3]\ttrain-mlogloss:0.76235\teval-mlogloss:0.77058\n",
      "[4]\ttrain-mlogloss:0.70565\teval-mlogloss:0.71641\n",
      "[5]\ttrain-mlogloss:0.65593\teval-mlogloss:0.66889\n",
      "[6]\ttrain-mlogloss:0.61206\teval-mlogloss:0.62757\n",
      "[7]\ttrain-mlogloss:0.57349\teval-mlogloss:0.59169\n",
      "[8]\ttrain-mlogloss:0.53869\teval-mlogloss:0.55944\n",
      "[9]\ttrain-mlogloss:0.50745\teval-mlogloss:0.53099\n",
      "[10]\ttrain-mlogloss:0.47991\teval-mlogloss:0.50630\n",
      "[11]\ttrain-mlogloss:0.45591\teval-mlogloss:0.48387\n",
      "[12]\ttrain-mlogloss:0.43435\teval-mlogloss:0.46327\n",
      "[13]\ttrain-mlogloss:0.41512\teval-mlogloss:0.44528\n",
      "[14]\ttrain-mlogloss:0.39804\teval-mlogloss:0.43016\n",
      "[15]\ttrain-mlogloss:0.38230\teval-mlogloss:0.41588\n",
      "[16]\ttrain-mlogloss:0.36819\teval-mlogloss:0.40310\n",
      "[17]\ttrain-mlogloss:0.35541\teval-mlogloss:0.39189\n",
      "[18]\ttrain-mlogloss:0.34360\teval-mlogloss:0.38212\n",
      "[19]\ttrain-mlogloss:0.33313\teval-mlogloss:0.37331\n",
      "[20]\ttrain-mlogloss:0.32330\teval-mlogloss:0.36466\n",
      "[21]\ttrain-mlogloss:0.31367\teval-mlogloss:0.35691\n",
      "[22]\ttrain-mlogloss:0.30546\teval-mlogloss:0.35062\n",
      "[23]\ttrain-mlogloss:0.29747\teval-mlogloss:0.34341\n",
      "[24]\ttrain-mlogloss:0.28950\teval-mlogloss:0.33756\n",
      "[25]\ttrain-mlogloss:0.28174\teval-mlogloss:0.33286\n",
      "[26]\ttrain-mlogloss:0.27513\teval-mlogloss:0.32842\n",
      "[27]\ttrain-mlogloss:0.26906\teval-mlogloss:0.32432\n",
      "[28]\ttrain-mlogloss:0.26330\teval-mlogloss:0.32084\n",
      "[29]\ttrain-mlogloss:0.25805\teval-mlogloss:0.31758\n",
      "[30]\ttrain-mlogloss:0.25321\teval-mlogloss:0.31401\n",
      "[31]\ttrain-mlogloss:0.24898\teval-mlogloss:0.31155\n",
      "[32]\ttrain-mlogloss:0.24479\teval-mlogloss:0.30877\n",
      "[33]\ttrain-mlogloss:0.24091\teval-mlogloss:0.30736\n",
      "[34]\ttrain-mlogloss:0.23768\teval-mlogloss:0.30559\n",
      "[35]\ttrain-mlogloss:0.23471\teval-mlogloss:0.30389\n",
      "[36]\ttrain-mlogloss:0.23201\teval-mlogloss:0.30212\n",
      "[37]\ttrain-mlogloss:0.22933\teval-mlogloss:0.30048\n",
      "[38]\ttrain-mlogloss:0.22708\teval-mlogloss:0.29919\n",
      "[39]\ttrain-mlogloss:0.22492\teval-mlogloss:0.29805\n",
      "[40]\ttrain-mlogloss:0.22277\teval-mlogloss:0.29741\n",
      "[41]\ttrain-mlogloss:0.22076\teval-mlogloss:0.29641\n",
      "[42]\ttrain-mlogloss:0.21909\teval-mlogloss:0.29486\n",
      "[43]\ttrain-mlogloss:0.21690\teval-mlogloss:0.29399\n",
      "[44]\ttrain-mlogloss:0.21464\teval-mlogloss:0.29400\n",
      "[45]\ttrain-mlogloss:0.21288\teval-mlogloss:0.29310\n",
      "[46]\ttrain-mlogloss:0.21065\teval-mlogloss:0.29295\n",
      "[47]\ttrain-mlogloss:0.20923\teval-mlogloss:0.29237\n",
      "[48]\ttrain-mlogloss:0.20772\teval-mlogloss:0.29152\n",
      "[49]\ttrain-mlogloss:0.20618\teval-mlogloss:0.29111\n",
      "[50]\ttrain-mlogloss:0.20499\teval-mlogloss:0.29098\n",
      "[51]\ttrain-mlogloss:0.20388\teval-mlogloss:0.29083\n",
      "[52]\ttrain-mlogloss:0.20179\teval-mlogloss:0.28991\n",
      "[53]\ttrain-mlogloss:0.20091\teval-mlogloss:0.28929\n",
      "[54]\ttrain-mlogloss:0.19990\teval-mlogloss:0.28922\n",
      "[55]\ttrain-mlogloss:0.19871\teval-mlogloss:0.28902\n",
      "[56]\ttrain-mlogloss:0.19742\teval-mlogloss:0.28812\n",
      "[57]\ttrain-mlogloss:0.19653\teval-mlogloss:0.28843\n",
      "[58]\ttrain-mlogloss:0.19459\teval-mlogloss:0.28764\n",
      "[59]\ttrain-mlogloss:0.19362\teval-mlogloss:0.28743\n",
      "[60]\ttrain-mlogloss:0.19277\teval-mlogloss:0.28752\n",
      "[61]\ttrain-mlogloss:0.19188\teval-mlogloss:0.28692\n",
      "[62]\ttrain-mlogloss:0.19096\teval-mlogloss:0.28647\n",
      "[63]\ttrain-mlogloss:0.18982\teval-mlogloss:0.28663\n",
      "[64]\ttrain-mlogloss:0.18915\teval-mlogloss:0.28677\n",
      "[65]\ttrain-mlogloss:0.18844\teval-mlogloss:0.28666\n",
      "[66]\ttrain-mlogloss:0.18780\teval-mlogloss:0.28679\n",
      "[67]\ttrain-mlogloss:0.18641\teval-mlogloss:0.28702\n",
      "[68]\ttrain-mlogloss:0.18570\teval-mlogloss:0.28720\n",
      "[69]\ttrain-mlogloss:0.18499\teval-mlogloss:0.28695\n",
      "[70]\ttrain-mlogloss:0.18397\teval-mlogloss:0.28661\n",
      "[71]\ttrain-mlogloss:0.18320\teval-mlogloss:0.28666\n",
      "[72]\ttrain-mlogloss:0.18263\teval-mlogloss:0.28663\n",
      "[73]\ttrain-mlogloss:0.18179\teval-mlogloss:0.28623\n",
      "[74]\ttrain-mlogloss:0.18041\teval-mlogloss:0.28578\n",
      "[75]\ttrain-mlogloss:0.17955\teval-mlogloss:0.28561\n",
      "[76]\ttrain-mlogloss:0.17889\teval-mlogloss:0.28542\n",
      "[77]\ttrain-mlogloss:0.17815\teval-mlogloss:0.28507\n",
      "[78]\ttrain-mlogloss:0.17705\teval-mlogloss:0.28577\n",
      "[79]\ttrain-mlogloss:0.17624\teval-mlogloss:0.28629\n",
      "[80]\ttrain-mlogloss:0.17567\teval-mlogloss:0.28627\n",
      "[81]\ttrain-mlogloss:0.17509\teval-mlogloss:0.28662\n",
      "[82]\ttrain-mlogloss:0.17408\teval-mlogloss:0.28762\n",
      "[83]\ttrain-mlogloss:0.17328\teval-mlogloss:0.28755\n",
      "[84]\ttrain-mlogloss:0.17247\teval-mlogloss:0.28786\n",
      "[85]\ttrain-mlogloss:0.17168\teval-mlogloss:0.28806\n",
      "[86]\ttrain-mlogloss:0.17096\teval-mlogloss:0.28832\n",
      "[87]\ttrain-mlogloss:0.16955\teval-mlogloss:0.28878\n",
      "[88]\ttrain-mlogloss:0.16846\teval-mlogloss:0.28951\n",
      "[89]\ttrain-mlogloss:0.16650\teval-mlogloss:0.28951\n",
      "[90]\ttrain-mlogloss:0.16540\teval-mlogloss:0.28981\n",
      "[91]\ttrain-mlogloss:0.16424\teval-mlogloss:0.28983\n",
      "[92]\ttrain-mlogloss:0.16249\teval-mlogloss:0.29111\n",
      "[93]\ttrain-mlogloss:0.16179\teval-mlogloss:0.29118\n",
      "[94]\ttrain-mlogloss:0.16082\teval-mlogloss:0.29159\n",
      "[95]\ttrain-mlogloss:0.16001\teval-mlogloss:0.29169\n",
      "[96]\ttrain-mlogloss:0.15918\teval-mlogloss:0.29117\n",
      "[97]\ttrain-mlogloss:0.15861\teval-mlogloss:0.29158\n",
      "[98]\ttrain-mlogloss:0.15793\teval-mlogloss:0.29141\n",
      "[99]\ttrain-mlogloss:0.15723\teval-mlogloss:0.29156\n",
      "[100]\ttrain-mlogloss:0.15667\teval-mlogloss:0.29184\n",
      "[101]\ttrain-mlogloss:0.15587\teval-mlogloss:0.29184\n",
      "[102]\ttrain-mlogloss:0.15479\teval-mlogloss:0.29177\n",
      "[103]\ttrain-mlogloss:0.15444\teval-mlogloss:0.29178\n",
      "[104]\ttrain-mlogloss:0.15385\teval-mlogloss:0.29204\n",
      "[105]\ttrain-mlogloss:0.15263\teval-mlogloss:0.29171\n",
      "[106]\ttrain-mlogloss:0.15135\teval-mlogloss:0.29198\n",
      "[107]\ttrain-mlogloss:0.15058\teval-mlogloss:0.29223\n",
      "[108]\ttrain-mlogloss:0.14997\teval-mlogloss:0.29203\n",
      "[109]\ttrain-mlogloss:0.14920\teval-mlogloss:0.29215\n",
      "[110]\ttrain-mlogloss:0.14799\teval-mlogloss:0.29207\n",
      "[111]\ttrain-mlogloss:0.14728\teval-mlogloss:0.29227\n",
      "[112]\ttrain-mlogloss:0.14681\teval-mlogloss:0.29236\n",
      "[113]\ttrain-mlogloss:0.14632\teval-mlogloss:0.29219\n",
      "[114]\ttrain-mlogloss:0.14535\teval-mlogloss:0.29265\n",
      "[115]\ttrain-mlogloss:0.14428\teval-mlogloss:0.29309\n",
      "[116]\ttrain-mlogloss:0.14393\teval-mlogloss:0.29326\n",
      "[117]\ttrain-mlogloss:0.14355\teval-mlogloss:0.29334\n",
      "[118]\ttrain-mlogloss:0.14237\teval-mlogloss:0.29414\n",
      "[119]\ttrain-mlogloss:0.14190\teval-mlogloss:0.29446\n",
      "[120]\ttrain-mlogloss:0.14075\teval-mlogloss:0.29483\n",
      "[121]\ttrain-mlogloss:0.13918\teval-mlogloss:0.29527\n",
      "[122]\ttrain-mlogloss:0.13838\teval-mlogloss:0.29571\n",
      "[123]\ttrain-mlogloss:0.13674\teval-mlogloss:0.29582\n",
      "[124]\ttrain-mlogloss:0.13584\teval-mlogloss:0.29615\n",
      "[125]\ttrain-mlogloss:0.13540\teval-mlogloss:0.29641\n",
      "[126]\ttrain-mlogloss:0.13500\teval-mlogloss:0.29653\n",
      "F1-score: 0.8657001351144862\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Преобразуем данные в DMatrix, который является основным форматом данных для XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Если у вас трёхклассовая задача, можно использовать:\n",
    "params = {\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"eta\": 0.1,\n",
    "    \"max_depth\": 6,\n",
    "    \"seed\": 42,\n",
    "    \"num_class\": 3,\n",
    "}\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"eval\")]\n",
    "\n",
    "# Обучаем модель\n",
    "num_rounds = 1000\n",
    "model_xgb = xgb.train(params, dtrain, num_boost_round=num_rounds, evals=evals, early_stopping_rounds=50)\n",
    "\n",
    "# Предсказываем на тестовом наборе\n",
    "y_pred = model_xgb.predict(dtest)\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "print(\"F1-score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
